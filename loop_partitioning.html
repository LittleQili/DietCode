
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Loop Partitioning &#8212; DietCode MLSys 2022 documentation</title>
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinxdoc.css" />
    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="Local Padding" href="local_padding.html" /> 
  </head><body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="local_padding.html" title="Local Padding"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="index.html">DietCode MLSys 2022 documentation</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">Loop Partitioning</a></li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="module-codegen.test_2_loop_partitioning">
<span id="loop-partitioning"></span><h1>Loop Partitioning<a class="headerlink" href="#module-codegen.test_2_loop_partitioning" title="Permalink to this headline">¶</a></h1>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><a class="reference internal" href="local_padding.html#module-codegen.test_1_local_padding" title="codegen.test_1_local_padding"><code class="xref py py-mod docutils literal notranslate"><span class="pre">codegen.test_1_local_padding</span></code></a></p>
</div>
<dl class="py function">
<dt class="sig sig-object py" id="codegen.test_2_loop_partitioning.test_loop_partitioning">
<span class="sig-prename descclassname"><span class="pre">codegen.test_2_loop_partitioning.</span></span><span class="sig-name descname"><span class="pre">test_loop_partitioning</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/UofT-EcoSystem/DietCode/blob/main/tests/codegen/test_2_loop_partitioning.py#L19-L107"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#codegen.test_2_loop_partitioning.test_loop_partitioning" title="Permalink to this definition">¶</a></dt>
<dd><p>This test case shows the performance improvement brought by loop
partitioning, used as an optimization technique in the <a class="reference internal" href="#nimble" id="id1"><span>[Nimble]</span></a> paper.
Similar to local padding, the goal of loop partitioning is also to mitigate
the performance overhead brought by out-of-boundary checks.</p>
<p>Given below is an example that illustrates how loop partitioning works:</p>
<div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="p">(</span><span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">ceil</span><span class="p">(</span><span class="n">T</span> <span class="o">/</span> <span class="n">t</span><span class="p">);</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span>
  <span class="k">for</span> <span class="p">(</span><span class="n">j</span> <span class="o">=</span> <span class="mi">0</span><span class="o">:</span> <span class="n">j</span> <span class="o">&lt;</span> <span class="n">t</span><span class="p">;</span> <span class="o">++</span><span class="n">j</span><span class="p">)</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">i</span> <span class="o">*</span> <span class="n">t</span> <span class="o">+</span> <span class="n">j</span> <span class="o">&lt;</span> <span class="n">T</span><span class="p">)</span> <span class="c1">// do something</span>
</pre></div>
</div>
<p>The above code snippet can be transformed into</p>
<div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="p">(</span><span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">floor</span><span class="p">(</span><span class="n">T</span> <span class="o">/</span> <span class="n">t</span><span class="p">);</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span>
  <span class="k">for</span> <span class="p">(</span><span class="n">j</span> <span class="o">=</span> <span class="mi">0</span><span class="o">:</span> <span class="n">j</span> <span class="o">&lt;</span> <span class="n">t</span><span class="p">;</span> <span class="o">++</span><span class="n">j</span><span class="p">)</span>
    <span class="c1">// do something</span>
<span class="k">for</span> <span class="p">(</span><span class="n">j</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">j</span> <span class="o">&lt;</span> <span class="n">T</span> <span class="o">-</span> <span class="n">floor</span><span class="p">(</span><span class="n">T</span> <span class="o">/</span> <span class="n">t</span><span class="p">)</span> <span class="o">*</span> <span class="n">t</span><span class="p">;</span> <span class="o">++</span><span class="n">j</span><span class="p">)</span>
  <span class="c1">// do something</span>
</pre></div>
</div>
<p>which does not have any predicates.</p>
<p>We compare the compute throughputs between two schedules, one without loop
partitioning (baseline) and the other with loop partitioning. The benchmark
we use is the same as the one in local padding
(<a class="reference internal" href="local_padding.html#codegen.test_1_local_padding.test_local_padding" title="codegen.test_1_local_padding.test_local_padding"><code class="xref py py-func docutils literal notranslate"><span class="pre">codegen.test_1_local_padding.test_local_padding()</span></code></a>). Our
evaluations show that loop partitioning can also significantly boost the
performance of the generated CUDA kernel by as much as <span class="math notranslate nohighlight">\(10\times\)</span>
(the same order of speedup as local padding). The table below illustrates
the results we get from the CI workflow:</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 41%" />
<col style="width: 30%" />
<col style="width: 30%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>GPU</p></th>
<th class="head"><p>Baseline</p></th>
<th class="head"><p>DietCode</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>RTX 3090</p></td>
<td><p>~0.98</p></td>
<td><p>~11.2</p></td>
</tr>
<tr class="row-odd"><td><p>RTX 2080 Ti</p></td>
<td><p>~0.43</p></td>
<td><p>~5.98</p></td>
</tr>
</tbody>
</table>
<p>where the numbers denote the compute throughputs (in TFLOPs/sec), and hence
the higher the better.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="codegen.test_2_loop_partitioning.test_loop_partitioning_ii">
<span class="sig-prename descclassname"><span class="pre">codegen.test_2_loop_partitioning.</span></span><span class="sig-name descname"><span class="pre">test_loop_partitioning_ii</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/UofT-EcoSystem/DietCode/blob/main/tests/codegen/test_2_loop_partitioning.py#L110-L176"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#codegen.test_2_loop_partitioning.test_loop_partitioning_ii" title="Permalink to this definition">¶</a></dt>
<dd><p>Therefore, one natural question to ask is:</p>
<p><strong>What is the difference between local padding and loop partitioning, given
that they share the same objective?</strong></p>
<p>Although the two techniques are indeed similar in what they are going to
achieve, we pick local padding primarily due to the following reasons:</p>
<ul class="simple">
<li><p>Due to the <em>partition</em> nature, <strong>loop partitioning needs to duplicate the
body statements</strong> (as can be seen in the simple example illustrated
before, where the comment <code class="docutils literal notranslate"><span class="pre">//</span> <span class="pre">do</span> <span class="pre">something</span></code> appears twice). Depending on
the number of spatial axes, this duplication can happen multiple times.
This can significantly elongate the CUDA kernel body, and further lead to
a gigantic kernel in the case when the original kernel body is already
long (e.g., because of a large unrolling factor), <strong>which eventually
increases the compilation time for the kernel</strong> (can be several minutes
for a single kernel by our measurements).</p></li>
<li><p><strong>There are cases that can be handled by local padding but NOT by loop
partitioning</strong>. We refer to the example below, which is again the same as
the one in local padding
(<a class="reference internal" href="local_padding.html#codegen.test_1_local_padding.test_local_padding_ii" title="codegen.test_1_local_padding.test_local_padding_ii"><code class="xref py py-func docutils literal notranslate"><span class="pre">codegen.test_1_local_padding.test_local_padding_ii()</span></code></a>).</p></li>
</ul>
<dl class="citation">
<dt class="label" id="nimble"><span class="brackets"><a class="fn-backref" href="#id1">Nimble</a></span></dt>
<dd><p>H. Shen et al. <em>Nimble: Efficiently Compiling Dynamic Neural
Networks for Model Inference</em>. MLSys 2021</p>
</dd>
</dl>
</dd></dl>

</div>


            <div class="clearer"></div>
          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <h4>Previous topic</h4>
  <p class="topless"><a href="local_padding.html"
                        title="previous chapter">Local Padding</a></p>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="_sources/loop_partitioning.rst.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="local_padding.html" title="Local Padding"
             >previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="index.html">DietCode MLSys 2022 documentation</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">Loop Partitioning</a></li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2022, University of Toronto, AWS, Vector Institute.
      Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 4.0.0.
    </div>
  </body>
</html>